from __future__ import annotations

import csv
import hmac
import json
import os
import re
from dataclasses import dataclass
from io import BytesIO, StringIO
from pathlib import Path
from tempfile import TemporaryDirectory
from typing import TYPE_CHECKING, Iterable

import streamlit as st

from enemane_ai.analyzer import (
    AVAILABLE_ARTICLE_THEMES,
    BUILDING_TYPES,
    CALENDAR_ANALYSIS_PROMPT,
    CALENDAR_OUTPUT_FORMAT,
    FLASH_MODEL_NAME,
    OUTPUT_FORMAT_INSTRUCTION,
    PRESET_PROMPT,
    ArticleProgressInfo,
    GeminiGraphLanguageModel,
    GraphLanguageModel,
    MonthlyPowerCalendarData,
    MonthlyReportData,
    MonthlyTemperatureSummary,
    analyze_image,
    build_power_calendar_extended_context,
    build_supplementary_context,
    collect_graph_entries,
    collect_relevant_articles,
    evaluate_summary_quality,
    parse_monthly_report_csv,
    parse_power_30min_csv,
    parse_temperature_csv_for_comparison,
    pdf_to_images,
    summarize_article,
)

if TYPE_CHECKING:
    from streamlit.runtime.uploaded_file_manager import UploadedFile


@dataclass
class AnalyzedGraph:
    label: str
    comment: str
    image_title: str | None = None
    item_name: str | None = None
    image_data: bytes | None = None
    text: str | None = None


@dataclass
class ResultRow:
    image_title: str
    item_name: str
    comment: str


@dataclass
class OutputRow:
    """target_data.csvå½¢å¼ã®1è¡Œ"""

    graph_name: str  # å¯¾å¿œã™ã‚‹ã‚°ãƒ©ãƒ•å
    item_name: str  # é …ç›®å
    ai_comment: str  # ç”Ÿæˆã™ã‚‹AIã‚³ãƒ¡ãƒ³ãƒˆ


@dataclass
class CalendarAnalysisRow:
    """é›»åŠ›ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼åˆ†æçµæœã®1è¡Œ"""

    item: str  # é …ç›®å(å…¨ä½“å‚¾å‘ã€æœ€å¤§éœ€è¦æ—¥ã®ç¢ºèªãªã©)
    analysis: str  # äº‹å®Ÿ+ä»®èª¬


@dataclass
class ArticleOutputRow:
    """è¨˜äº‹æ¤œç´¢çµæœCSVã®1è¡Œ"""

    theme: str  # ãƒ†ãƒ¼ãƒ
    title: str  # ã‚¿ã‚¤ãƒˆãƒ«
    content: str  # æœ¬æ–‡(è¦ç´„)
    image: str  # ç”»åƒURL
    link: str  # ãƒªãƒ³ã‚¯


def save_uploads_to_temp(files: Iterable["UploadedFile"], tmpdir: Path) -> list[Path]:
    saved_paths: list[Path] = []
    for file in files:
        destination = tmpdir / file.name
        destination.write_bytes(file.getvalue())
        saved_paths.append(destination)
    return saved_paths


def analyze_files(
    file_paths: list[Path],
    prompt: str,
    llm: GraphLanguageModel | None = None,
) -> list[AnalyzedGraph]:
    entries = collect_graph_entries(file_paths)
    analyzed: list[AnalyzedGraph] = []
    for entry in entries:
        if entry.image is not None:
            comment_prompt = build_image_prompt(prompt)
            raw_comment = analyze_image(entry.image, prompt=comment_prompt, llm=llm)
            image_title, item_name, comment = parse_structured_comment(
                raw_comment, fallback_label=entry.display_label
            )
            buffer = BytesIO()
            entry.image.save(buffer, format="PNG")
            analyzed.append(
                AnalyzedGraph(
                    label=entry.display_label,
                    comment=comment,
                    image_title=image_title,
                    item_name=item_name,
                    image_data=buffer.getvalue(),
                )
            )
            continue

        if entry.text is not None:
            analyzed.append(
                AnalyzedGraph(
                    label=entry.display_label,
                    comment="",
                    image_title=entry.display_label,
                    item_name="ãƒ†ã‚­ã‚¹ãƒˆ/CSV",
                    text=entry.text,
                )
            )
    return analyzed


def resolve_gemini_client() -> GeminiGraphLanguageModel | None:
    api_key = st.secrets.get("GEMINI_API_KEY") if hasattr(st, "secrets") else None
    api_key = api_key or os.getenv("GEMINI_API_KEY")
    if not api_key:
        st.error(
            "GEMINI_API_KEY ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"
            " .streamlit/secrets.toml ã«è¨­å®šã—ã¦ãã ã•ã„ (ç’°å¢ƒå¤‰æ•° GEMINI_API_KEY ã§ã‚‚å¯)ã€‚"
        )
        return None

    try:
        return GeminiGraphLanguageModel(api_key=api_key)
    except Exception as exc:
        st.error(f"Gemini ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}")
        return None


def strip_code_fence(text: str) -> str:
    stripped = text.strip()
    if stripped.startswith("```") and stripped.endswith("```"):
        lines = stripped.splitlines()
        if len(lines) >= 2:
            return "\n".join(lines[1:-1])
    return text


def strip_markdown(text: str) -> str:
    # Bold: **text** or __text__
    text = re.sub(r"(\*\*|__)(.*?)\1", r"\2", text)
    # Italic: *text* or _text_
    text = re.sub(r"(\*|_)(.*?)\1", r"\2", text)
    # Links: [text](url) -> text
    text = re.sub(r"\[([^\]]+)\]\([^)]+\)", r"\1", text)
    # Inline code: `text` -> text
    text = re.sub(r"`([^`]+)`", r"\1", text)
    # Headers: # text -> text (remove leading # and space)
    text = re.sub(r"^#+\s*", "", text, flags=re.MULTILINE)
    # List markers: - text, * text -> text (remove leading marker and space)
    text = re.sub(r"^[\*\-]\s+", "", text, flags=re.MULTILINE)
    return text.strip()


def parse_structured_comment(raw_comment: str, fallback_label: str) -> tuple[str, str, str]:
    cleaned = strip_code_fence(raw_comment)
    try:
        data = json.loads(cleaned)
    except json.JSONDecodeError:
        return fallback_label, fallback_label, raw_comment

    if not isinstance(data, dict):
        return fallback_label, fallback_label, raw_comment

    image_title = str(data.get("image_title") or fallback_label)
    item_name = str(data.get("item_name") or fallback_label)
    comment = str(data.get("comment") or raw_comment)
    return image_title, item_name, comment


def parse_multi_item_response(
    raw_response: str,
    fallback_graph_name: str,
) -> list[tuple[str, str, str]]:
    """
    JSONé…åˆ—ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’(graph_name, item_name, comment)ã®ãƒªã‚¹ãƒˆã«å¤‰æ›ã€‚

    ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒJSONé…åˆ—ã®å ´åˆã¯è¤‡æ•°é …ç›®ã‚’è¿”ã—ã€
    å˜ä¸€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¾ãŸã¯ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚
    """
    cleaned = strip_code_fence(raw_response)
    try:
        data = json.loads(cleaned)
    except json.JSONDecodeError:
        # JSONãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ãŸå ´åˆã€å˜ä¸€é …ç›®ã¨ã—ã¦è¿”ã™
        return [(fallback_graph_name, "", raw_response)]

    if isinstance(data, list):
        results: list[tuple[str, str, str]] = []
        for item in data:
            if not isinstance(item, dict):
                continue
            graph_name = str(item.get("graph_name") or fallback_graph_name)
            item_name = str(item.get("item_name") or "")
            comment = str(item.get("comment") or "")
            results.append((graph_name, item_name, comment))
        if results:
            return results
        # ç©ºã®é…åˆ—ã®å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        return [(fallback_graph_name, "", raw_response)]

    if isinstance(data, dict):
        # å˜ä¸€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆ(å¾Œæ–¹äº’æ›æ€§)
        graph_name = str(data.get("graph_name") or data.get("image_title") or fallback_graph_name)
        item_name = str(data.get("item_name") or "")
        comment = str(data.get("comment") or "")
        return [(graph_name, item_name, comment)]

    return [(fallback_graph_name, "", raw_response)]


def parse_calendar_analysis_response(raw_response: str) -> list[CalendarAnalysisRow]:
    """
    ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼åˆ†æã®JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’CalendarAnalysisRowã®ãƒªã‚¹ãƒˆã«å¤‰æ›ã€‚

    æœŸå¾…å½¢å¼:
    [{"item": "å…¨ä½“å‚¾å‘", "analysis": "..."}, ...]
    """
    cleaned = strip_code_fence(raw_response)
    try:
        data = json.loads(cleaned)
    except json.JSONDecodeError:
        # JSONãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ãŸå ´åˆã€å˜ä¸€é …ç›®ã¨ã—ã¦è¿”ã™
        return [CalendarAnalysisRow(item="åˆ†æçµæœ", analysis=raw_response)]

    if isinstance(data, list):
        results: list[CalendarAnalysisRow] = []
        for item in data:
            if not isinstance(item, dict):
                continue
            item_name = str(item.get("item") or "")
            analysis = str(item.get("analysis") or "")
            if item_name or analysis:
                results.append(
                    CalendarAnalysisRow(
                        item=strip_markdown(item_name),
                        analysis=strip_markdown(analysis),
                    )
                )
        if results:
            return results
        return [CalendarAnalysisRow(item="åˆ†æçµæœ", analysis=raw_response)]

    if isinstance(data, dict):
        item_name = str(data.get("item") or "åˆ†æçµæœ")
        analysis = str(data.get("analysis") or "")
        return [
            CalendarAnalysisRow(
                item=strip_markdown(item_name),
                analysis=strip_markdown(analysis),
            )
        ]

    return [CalendarAnalysisRow(item="åˆ†æçµæœ", analysis=raw_response)]


def export_calendar_analysis_csv(rows: list[CalendarAnalysisRow]) -> bytes:
    """ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼åˆ†æçµæœã‚’CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ(BOMä»˜ãUTF-8)ã€‚"""
    buffer = StringIO()
    writer = csv.writer(buffer)
    writer.writerow(["é …ç›®", "äº‹å®Ÿ+ä»®èª¬"])
    for row in rows:
        writer.writerow([row.item, row.analysis])
    return ("\ufeff" + buffer.getvalue()).encode("utf-8")


def export_article_search_csv(rows: list[ArticleOutputRow]) -> bytes:
    """è¨˜äº‹æ¤œç´¢çµæœã‚’CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ(BOMä»˜ãUTF-8)ã€‚"""
    buffer = StringIO()
    writer = csv.writer(buffer)
    writer.writerow(["ãƒ†ãƒ¼ãƒ", "ã‚¿ã‚¤ãƒˆãƒ«", "æœ¬æ–‡", "ç”»åƒ", "ãƒªãƒ³ã‚¯"])
    for row in rows:
        writer.writerow([row.theme, row.title, row.content, row.image, row.link])
    return ("\ufeff" + buffer.getvalue()).encode("utf-8")


def build_image_prompt(base_prompt: str) -> str:
    return (
        f"{base_prompt}\n\n"
        "ä»¥ä¸‹ã®3ã¤ã®å€¤ã‚’å«ã‚€ JSON æ–‡å­—åˆ—ã ã‘ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚\n"
        '{ "image_title": "ç”»åƒä¸Šéƒ¨ã®ã‚¿ã‚¤ãƒˆãƒ«", "item_name": "ã‚°ãƒ©ãƒ•ä¸Šã®åç§°", "comment": "1) ãƒˆãƒ¬ãƒ³ãƒ‰ 2) å«æ„ 3) æ³¨æ„ç‚¹" }\n'  # noqa: E501
        "æ—¥æœ¬èªã§ç°¡æ½”ã«ã€‚"
    )


def build_result_rows(analyzed: list[AnalyzedGraph]) -> list[ResultRow]:
    rows: list[ResultRow] = []
    for item in analyzed:
        if item.image_data is None:
            continue  # CSV/ãƒ†ã‚­ã‚¹ãƒˆã¯è¡¨ã‹ã‚‰é™¤å¤–
        image_title = item.image_title or item.label
        item_name = item.item_name
        if item_name is None:
            item_name = "ã‚°ãƒ©ãƒ•ç”»åƒ" if item.image_data is not None else "ãƒ†ã‚­ã‚¹ãƒˆ/CSV"
        comment = item.comment
        if not comment and item.text is not None:
            comment = "CSV/ãƒ†ã‚­ã‚¹ãƒˆã¯ã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆã‚’çœç•¥ã—ã¦ã„ã¾ã™ã€‚"

        # ãƒ†ãƒ¼ãƒ–ãƒ«å‡ºåŠ›ç”¨ã«Markdownã‚’é™¤å»ã—ã¦ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåŒ–
        rows.append(
            ResultRow(
                image_title=strip_markdown(image_title),
                item_name=strip_markdown(item_name),
                comment=strip_markdown(comment),
            )
        )
    return rows


def export_table_csv(rows: list[ResultRow]) -> bytes:
    buffer = StringIO()
    writer = csv.writer(buffer)
    writer.writerow(["ç”»åƒå†…ã‚¿ã‚¤ãƒˆãƒ«", "é …ç›®å", "AIã§ç”Ÿæˆã—ãŸã‚³ãƒ¡ãƒ³ãƒˆ"])
    for row in rows:
        writer.writerow([row.image_title, row.item_name, row.comment])
    # Shift_JIS (CP932) ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ (Windows Excelã§ç¢ºå®Ÿã«é–‹ã‘ã‚‹)
    return buffer.getvalue().encode("cp932", errors="replace")


def export_target_format_csv(results: list[OutputRow]) -> bytes:
    """target_data.csvå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ(BOMä»˜ãUTF-8)ã€‚"""
    buffer = StringIO()
    writer = csv.writer(buffer)
    writer.writerow(["å¯¾å¿œã™ã‚‹ã‚°ãƒ©ãƒ•å", "é …ç›®å", "ç”Ÿæˆã™ã‚‹AIã‚³ãƒ¡ãƒ³ãƒˆ"])
    for row in results:
        writer.writerow([row.graph_name, row.item_name, row.ai_comment])
    # BOMä»˜ãUTF-8ã§Exceläº’æ›æ€§ã‚’ç¢ºä¿
    return ("\ufeff" + buffer.getvalue()).encode("utf-8")


def analyze_graphs_with_context(
    graph_paths: list[Path],
    monthly_report: MonthlyReportData | None,
    temperature: tuple[MonthlyTemperatureSummary, MonthlyTemperatureSummary] | None,
    base_prompt: str,
    llm: GraphLanguageModel,
) -> list[OutputRow]:
    """
    ã‚°ãƒ©ãƒ•ç”»åƒã‚’è£œåŠ©ãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä»˜ãã§åˆ†æã—ã€OutputRowã®ãƒªã‚¹ãƒˆã‚’è¿”ã™ã€‚
    """
    # è£œåŠ©ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
    context = build_supplementary_context(monthly_report, temperature)

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
    full_prompt = base_prompt
    if context:
        full_prompt = f"{base_prompt}\n\n{context}"
    full_prompt = f"{full_prompt}\n\n{OUTPUT_FORMAT_INSTRUCTION}"

    all_results: list[OutputRow] = []
    entries = collect_graph_entries(graph_paths)

    for entry in entries:
        if entry.image is None:
            continue

        raw_response = analyze_image(entry.image, prompt=full_prompt, llm=llm)
        items = parse_multi_item_response(raw_response, entry.display_label)

        for graph_name, item_name, comment in items:
            all_results.append(
                OutputRow(
                    graph_name=strip_markdown(graph_name),
                    item_name=strip_markdown(item_name),
                    ai_comment=strip_markdown(comment),
                )
            )

    return all_results


def check_password() -> bool:
    """Basicèªè¨¼ã‚’è¡Œã„ã€èªè¨¼æˆåŠŸãªã‚‰Trueã‚’è¿”ã™ã€‚"""

    def password_entered() -> None:
        """ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å…¥åŠ›æ™‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚"""
        if hmac.compare_digest(
            st.session_state["username"], st.secrets.auth.username
        ) and hmac.compare_digest(st.session_state["password"], st.secrets.auth.password):
            st.session_state["password_correct"] = True
            del st.session_state["password"]
            del st.session_state["username"]
        else:
            st.session_state["password_correct"] = False

    if st.session_state.get("password_correct", False):
        return True

    st.text_input("ãƒ¦ãƒ¼ã‚¶ãƒ¼å", key="username")
    st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password", key="password")
    st.button("ãƒ­ã‚°ã‚¤ãƒ³", on_click=password_entered)

    if "password_correct" in st.session_state and not st.session_state["password_correct"]:
        st.error("ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¾ãŸã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“")

    return False


def render_graph_analysis_tab() -> None:
    """ã‚°ãƒ©ãƒ•åˆ†æã‚¿ãƒ–ã®UIã‚’æç”»ã€‚"""
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if "graph_analysis_results" not in st.session_state:
        st.session_state.graph_analysis_results = None

    st.caption(
        "ã‚°ãƒ©ãƒ•ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€æœˆå ±CSVãƒ»æ°—æ¸©ãƒ‡ãƒ¼ã‚¿ã¨çµ„ã¿åˆã‚ã›ã¦AIã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚"
    )

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’3ã¤ã«åˆ†é›¢
    st.subheader("1. ã‚°ãƒ©ãƒ•ç”»åƒ")
    graph_files = st.file_uploader(
        "åˆ†æã—ãŸã„ã‚°ãƒ©ãƒ•ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
        type=["png", "jpg", "jpeg", "pdf"],
        accept_multiple_files=True,
        key="graph_images",
    )

    st.subheader("2. è£œåŠ©ãƒ‡ãƒ¼ã‚¿ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)")
    col1, col2 = st.columns(2)

    with col1:
        monthly_report_file = st.file_uploader(
            "æœˆå ±CSV (å‰å¹´åŒæœˆãƒ‡ãƒ¼ã‚¿)",
            type=["csv"],
            accept_multiple_files=False,
            key="monthly_report",
            help="å‰å¹´åŒæœˆã®é›»åŠ›ä½¿ç”¨é‡ãƒ‡ãƒ¼ã‚¿ã€‚å‰å¹´æ¯”è¼ƒã«ä½¿ç”¨ã—ã¾ã™ã€‚",
        )

    with col2:
        temperature_file = st.file_uploader(
            "æ°—æ¸©ãƒ‡ãƒ¼ã‚¿CSV (å‰å¹´ãƒ»å½“å¹´)",
            type=["csv"],
            accept_multiple_files=False,
            key="temperature",
            help="å‰å¹´ã¨å½“å¹´ã®æ°—æ¸©ãƒ‡ãƒ¼ã‚¿ã€‚æ°—æ¸©ã¨ã®ç›¸é–¢åˆ†æã«ä½¿ç”¨ã—ã¾ã™ã€‚",
        )

    st.subheader("3. è¿½åŠ æŒ‡ç¤º (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)")
    additional_instructions = st.text_area(
        "è¿½åŠ ã®æŒ‡ç¤º",
        placeholder="ä¾‹: é‡è¦ãªãƒˆãƒ¬ãƒ³ãƒ‰ã®ã¿ã‚’ç®‡æ¡æ›¸ãã§ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚",
        height=80,
        key="graph_additional_instructions",
    )

    prompt = PRESET_PROMPT
    if additional_instructions.strip():
        prompt = f"{PRESET_PROMPT}\n\n{additional_instructions.strip()}"

    if not graph_files:
        st.info("ã‚°ãƒ©ãƒ•ç”»åƒã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return

    if st.button("åˆ†æã‚’å®Ÿè¡Œ", type="primary", key="graph_analyze_button"):
        llm = resolve_gemini_client()
        if llm is None:
            return

        with st.status("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æº–å‚™ã—ã¦ã„ã¾ã™...", expanded=False) as status:
            with TemporaryDirectory() as tmpdir_str:
                tmpdir = Path(tmpdir_str)

                # ã‚°ãƒ©ãƒ•ç”»åƒã‚’ä¿å­˜
                graph_paths = save_uploads_to_temp(graph_files, tmpdir)

                # æœˆå ±CSVã‚’ãƒ‘ãƒ¼ã‚¹
                monthly_report: MonthlyReportData | None = None
                if monthly_report_file:
                    report_path = tmpdir / monthly_report_file.name
                    report_path.write_bytes(monthly_report_file.getvalue())
                    try:
                        monthly_report = parse_monthly_report_csv(report_path)
                        st.info(
                            f"æœˆå ±ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {monthly_report.month_label}, "
                            f"æœˆé–“é›»åŠ›ä½¿ç”¨é‡: {monthly_report.total_power_monthly:,.0f} kWh"
                        )
                    except Exception as exc:
                        st.warning(f"æœˆå ±CSVã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}")

                # æ°—æ¸©ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‘ãƒ¼ã‚¹
                temperature: tuple[MonthlyTemperatureSummary, MonthlyTemperatureSummary] | None = (
                    None
                )
                if temperature_file:
                    temp_path = tmpdir / temperature_file.name
                    temp_path.write_bytes(temperature_file.getvalue())
                    try:
                        temperature = parse_temperature_csv_for_comparison(temp_path)
                        prev, curr = temperature
                        st.info(
                            f"æ°—æ¸©ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {prev.year_month} â†’ {curr.year_month}, "
                            f"å¹³å‡æ°—æ¸©å·®: {curr.avg_temp - prev.avg_temp:+.1f}â„ƒ"
                        )
                    except Exception as exc:
                        st.warning(f"æ°—æ¸©CSVã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}")

                status.update(label="åˆ†æä¸­...", state="running")
                try:
                    results = analyze_graphs_with_context(
                        graph_paths=graph_paths,
                        monthly_report=monthly_report,
                        temperature=temperature,
                        base_prompt=prompt,
                        llm=llm,
                    )
                except Exception as exc:
                    status.update(label="å¤±æ•—", state="error")
                    st.error(f"åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}")
                    return
            status.update(label="å®Œäº†", state="complete")

        # çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
        st.session_state.graph_analysis_results = results

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰çµæœã‚’è¡¨ç¤º
    if st.session_state.graph_analysis_results is not None:
        results = st.session_state.graph_analysis_results

        st.subheader("çµæœ")

        if not results:
            st.warning("åˆ†æçµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
            st.markdown("#### ãƒ†ãƒ¼ãƒ–ãƒ«å‡ºåŠ›")
            table_data = [
                {
                    "å¯¾å¿œã™ã‚‹ã‚°ãƒ©ãƒ•å": row.graph_name,
                    "é …ç›®å": row.item_name,
                    "ç”Ÿæˆã™ã‚‹AIã‚³ãƒ¡ãƒ³ãƒˆ": row.ai_comment,
                }
                for row in results
            ]
            st.table(table_data)

            # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            st.download_button(
                "CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=export_target_format_csv(results),
                file_name="analysis_results.csv",
                mime="text/csv",
                key="graph_download_button",
            )


def render_calendar_analysis_tab() -> None:
    """é›»åŠ›ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼åˆ†æã‚¿ãƒ–ã®UIã‚’æç”»ã€‚"""
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if "calendar_analysis_results" not in st.session_state:
        st.session_state.calendar_analysis_results = None
    if "calendar_analysis_curr_power" not in st.session_state:
        st.session_state.calendar_analysis_curr_power = None
    if "calendar_analysis_prev_power" not in st.session_state:
        st.session_state.calendar_analysis_prev_power = None
    if "calendar_analysis_temperature" not in st.session_state:
        st.session_state.calendar_analysis_temperature = None

    st.caption(
        "é›»åŠ›ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼PDFã¨30åˆ†é–“éš”é›»åŠ›CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€"
        "AIãŒäº‹å®Ÿ+ä»®èª¬ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’è¡¨å½¢å¼ã§ç”Ÿæˆã—ã¾ã™ã€‚"
        "å‰å¹´ãƒ‡ãƒ¼ã‚¿ã‚„æ°—æ¸©ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã™ã‚‹ã¨ã€ã‚ˆã‚Šè©³ç´°ãªåˆ†æãŒå¯èƒ½ã§ã™ã€‚"
    )

    st.subheader("1. é›»åŠ›ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼PDF")
    calendar_pdf = st.file_uploader(
        "é›»åŠ›ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
        type=["pdf"],
        accept_multiple_files=False,
        key="calendar_pdf",
        help="æ—¥åˆ¥ã®30åˆ†åˆ»ã¿é›»åŠ›ä½¿ç”¨é‡æ¨ç§»ã‚°ãƒ©ãƒ•ãŒå«ã¾ã‚Œã‚‹PDF",
    )

    st.subheader("2. é›»åŠ›ãƒ‡ãƒ¼ã‚¿")
    col_power1, col_power2 = st.columns(2)

    with col_power1:
        power_csv = st.file_uploader(
            "å½“å¹´30åˆ†é–“éš”é›»åŠ›CSV (å¿…é ˆ)",
            type=["csv"],
            accept_multiple_files=False,
            key="power_csv",
            help="å½¢å¼: æ—¥æ™‚, kWhå€¤ (ä¾‹: 2024-10-01 00:00, 4.29)",
        )

    with col_power2:
        prev_power_csv = st.file_uploader(
            "å‰å¹´30åˆ†é–“éš”é›»åŠ›CSV (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)",
            type=["csv"],
            accept_multiple_files=False,
            key="prev_power_csv",
            help="å‰å¹´åŒæœˆã®é›»åŠ›ãƒ‡ãƒ¼ã‚¿ã€‚å‰å¹´æ¯”è¼ƒåˆ†æã«ä½¿ç”¨ã—ã¾ã™ã€‚",
        )

    st.subheader("3. æ°—æ¸©ãƒ‡ãƒ¼ã‚¿ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)")
    temperature_csv = st.file_uploader(
        "æ°—æ¸©CSV (å‰å¹´ãƒ»å½“å¹´ã®2å¹´åˆ†)",
        type=["csv"],
        accept_multiple_files=False,
        key="calendar_temperature_csv",
        help="å½¢å¼: æ—¥ä»˜æ™‚åˆ», æ°—æ¸© (ä¾‹: 2024/10/1 1:00, 25.0)ã€‚æ°—æ¸©ã¨ã®ç›¸é–¢åˆ†æã«ä½¿ç”¨ã—ã¾ã™ã€‚",
    )

    st.subheader("4. è¿½åŠ æŒ‡ç¤º (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)")
    additional_instructions = st.text_area(
        "è¿½åŠ ã®æŒ‡ç¤º",
        placeholder="ä¾‹: çœã‚¨ãƒæ”¹å–„ã®ç¤ºå”†ã‚’é‡ç‚¹çš„ã«åˆ†æã—ã¦ãã ã•ã„ã€‚",
        height=80,
        key="calendar_additional_instructions",
    )

    if not calendar_pdf or not power_csv:
        st.info("é›»åŠ›ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼PDFã¨å½“å¹´30åˆ†é–“éš”é›»åŠ›CSVã®ä¸¡æ–¹ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return

    if st.button("åˆ†æã‚’å®Ÿè¡Œ", type="primary", key="calendar_analyze_button"):
        llm = resolve_gemini_client()
        if llm is None:
            return

        with st.status("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æº–å‚™ã—ã¦ã„ã¾ã™...", expanded=False) as status:
            with TemporaryDirectory() as tmpdir_str:
                tmpdir = Path(tmpdir_str)

                # PDFã‚’ä¿å­˜
                pdf_path = tmpdir / calendar_pdf.name
                pdf_path.write_bytes(calendar_pdf.getvalue())

                # å½“å¹´é›»åŠ›CSVã‚’ä¿å­˜ã—ã¦ãƒ‘ãƒ¼ã‚¹
                csv_path = tmpdir / power_csv.name
                csv_path.write_bytes(power_csv.getvalue())

                try:
                    curr_power_data = parse_power_30min_csv(csv_path)
                    st.info(
                        f"å½“å¹´é›»åŠ›ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {curr_power_data.year_month}, "
                        f"æœˆé–“é›»åŠ›ä½¿ç”¨é‡: {curr_power_data.total_monthly_kwh:,.1f} kWh"
                    )
                except Exception as exc:
                    status.update(label="å¤±æ•—", state="error")
                    st.error(f"å½“å¹´é›»åŠ›CSVã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}")
                    return

                # å‰å¹´é›»åŠ›CSVã‚’ãƒ‘ãƒ¼ã‚¹ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
                prev_power_data: MonthlyPowerCalendarData | None = None
                if prev_power_csv:
                    prev_csv_path = tmpdir / prev_power_csv.name
                    prev_csv_path.write_bytes(prev_power_csv.getvalue())
                    try:
                        prev_power_data = parse_power_30min_csv(prev_csv_path)
                        st.info(
                            f"å‰å¹´é›»åŠ›ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {prev_power_data.year_month}, "
                            f"æœˆé–“é›»åŠ›ä½¿ç”¨é‡: {prev_power_data.total_monthly_kwh:,.1f} kWh"
                        )
                    except Exception as exc:
                        st.warning(f"å‰å¹´é›»åŠ›CSVã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}")

                # æ°—æ¸©CSVã‚’ãƒ‘ãƒ¼ã‚¹ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
                temperature_data: (
                    tuple[MonthlyTemperatureSummary, MonthlyTemperatureSummary] | None
                ) = None
                if temperature_csv:
                    temp_path = tmpdir / temperature_csv.name
                    temp_path.write_bytes(temperature_csv.getvalue())
                    try:
                        temperature_data = parse_temperature_csv_for_comparison(temp_path)
                        prev_temp, curr_temp = temperature_data
                        st.info(
                            f"æ°—æ¸©ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {prev_temp.year_month} â†’ {curr_temp.year_month}, "
                            f"å¹³å‡æ°—æ¸©å·®: {curr_temp.avg_temp - prev_temp.avg_temp:+.1f}â„ƒ"
                        )
                    except Exception as exc:
                        st.warning(f"æ°—æ¸©CSVã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}")

                # PDFã‚’ç”»åƒã«å¤‰æ›
                status.update(label="PDFã‚’å‡¦ç†ä¸­...", state="running")
                try:
                    pdf_images = pdf_to_images(pdf_path)
                    if not pdf_images:
                        status.update(label="å¤±æ•—", state="error")
                        st.error("PDFã‹ã‚‰ç”»åƒã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                        return
                    # æœ€åˆã®ãƒšãƒ¼ã‚¸ã‚’ä½¿ç”¨
                    _, calendar_image = pdf_images[0]
                except Exception as exc:
                    status.update(label="å¤±æ•—", state="error")
                    st.error(f"PDFå‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}")
                    return

                # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰ (æ‹¡å¼µç‰ˆã‚’ä½¿ç”¨)
                context = build_power_calendar_extended_context(
                    curr_power=curr_power_data,
                    prev_power=prev_power_data,
                    temperature=temperature_data,
                )

                # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
                full_prompt = CALENDAR_ANALYSIS_PROMPT
                if additional_instructions.strip():
                    full_prompt = f"{full_prompt}\n\n{additional_instructions.strip()}"
                full_prompt = f"{full_prompt}\n\n{context}\n\n{CALENDAR_OUTPUT_FORMAT}"

                # AIåˆ†æã‚’å®Ÿè¡Œ
                status.update(label="åˆ†æä¸­...", state="running")
                try:
                    raw_response = analyze_image(calendar_image, prompt=full_prompt, llm=llm)
                    results = parse_calendar_analysis_response(raw_response)
                except Exception as exc:
                    status.update(label="å¤±æ•—", state="error")
                    st.error(f"åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}")
                    return

            status.update(label="å®Œäº†", state="complete")

        # çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
        st.session_state.calendar_analysis_results = results
        st.session_state.calendar_analysis_curr_power = curr_power_data
        st.session_state.calendar_analysis_prev_power = prev_power_data
        st.session_state.calendar_analysis_temperature = temperature_data

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰çµæœã‚’è¡¨ç¤º
    if st.session_state.calendar_analysis_results is not None:
        results = st.session_state.calendar_analysis_results
        curr_power_data = st.session_state.calendar_analysis_curr_power
        prev_power_data = st.session_state.calendar_analysis_prev_power
        temperature_data = st.session_state.calendar_analysis_temperature

        # çµæœè¡¨ç¤º
        st.subheader("çµæœ")

        # åˆ†æã‚µãƒãƒªãƒ¼
        st.markdown("#### åˆ†æã‚µãƒãƒªãƒ¼")
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ãƒ‡ãƒ¼ã‚¿æœŸé–“", curr_power_data.year_month)
        with col2:
            # å‰å¹´ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯å‰å¹´æ¯”ã‚’è¡¨ç¤º
            if prev_power_data:
                diff = curr_power_data.total_monthly_kwh - prev_power_data.total_monthly_kwh
                pct = (
                    (diff / prev_power_data.total_monthly_kwh * 100)
                    if prev_power_data.total_monthly_kwh > 0
                    else 0
                )
                st.metric(
                    "æœˆé–“é›»åŠ›ä½¿ç”¨é‡",
                    f"{curr_power_data.total_monthly_kwh:,.0f} kWh",
                    delta=f"{diff:+,.0f} kWh ({pct:+.1f}%)",
                )
            else:
                st.metric("æœˆé–“é›»åŠ›ä½¿ç”¨é‡", f"{curr_power_data.total_monthly_kwh:,.0f} kWh")

        col3, col4 = st.columns(2)
        with col3:
            st.metric(
                "æœ€å¤§é›»åŠ›ä½¿ç”¨é‡æ—¥",
                curr_power_data.max_usage_day,
                help="1æ—¥ã®åˆè¨ˆé›»åŠ›ä½¿ç”¨é‡(kWh)ãŒæœ€å¤§ã®æ—¥",
            )
        with col4:
            st.metric(
                "æœ€å¤§éœ€è¦é›»åŠ›æ—¥",
                curr_power_data.max_demand_day,
                help="30åˆ†é–“éš”ã®ãƒ”ãƒ¼ã‚¯å€¤(kW)ãŒæœ€å¤§ã®æ—¥",
            )

        col5, col6 = st.columns(2)
        with col5:
            st.metric("å¹³æ—¥å¹³å‡", f"{curr_power_data.weekday_avg_kwh:,.1f} kWh/æ—¥")
        with col6:
            st.metric("ä¼‘æ—¥å¹³å‡", f"{curr_power_data.weekend_avg_kwh:,.1f} kWh/æ—¥")

        # æ°—æ¸©ã‚µãƒãƒªãƒ¼ (ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆ)
        if temperature_data:
            prev_temp, curr_temp = temperature_data
            st.markdown("#### æ°—æ¸©ã‚µãƒãƒªãƒ¼")
            col_temp1, col_temp2 = st.columns(2)
            with col_temp1:
                st.metric("å½“å¹´å¹³å‡æ°—æ¸©", f"{curr_temp.avg_temp:.1f}â„ƒ")
            with col_temp2:
                temp_diff = curr_temp.avg_temp - prev_temp.avg_temp
                st.metric(
                    "å‰å¹´å¹³å‡æ°—æ¸©",
                    f"{prev_temp.avg_temp:.1f}â„ƒ",
                    delta=f"{temp_diff:+.1f}â„ƒ (å½“å¹´ã¨ã®å·®)",
                )

        # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
        st.markdown("#### ãƒ†ãƒ¼ãƒ–ãƒ«å‡ºåŠ›")
        table_data = [{"é …ç›®": row.item, "äº‹å®Ÿ+ä»®èª¬": row.analysis} for row in results]
        st.table(table_data)

        # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        st.download_button(
            "CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=export_calendar_analysis_csv(results),
            file_name="calendar_analysis_results.csv",
            mime="text/csv",
            key="calendar_download_button",
        )


def resolve_gemini_client_with_model(
    model_name: str,
) -> GeminiGraphLanguageModel | None:
    """æŒ‡å®šãƒ¢ãƒ‡ãƒ«ã§Geminiã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚"""
    api_key = st.secrets.get("GEMINI_API_KEY") if hasattr(st, "secrets") else None
    api_key = api_key or os.getenv("GEMINI_API_KEY")
    if not api_key:
        st.error("GEMINI_API_KEY ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚secrets.toml ã¾ãŸã¯ç’°å¢ƒå¤‰æ•°ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        return None

    try:
        return GeminiGraphLanguageModel(api_key=api_key, model_name=model_name)
    except Exception as exc:
        st.error(f"Gemini ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}")
        return None


def render_article_search_tab() -> None:
    """è¨˜äº‹æ¤œç´¢ãƒ»è¦ç´„ã‚¿ãƒ–ã®UIã‚’æç”»ã€‚"""
    st.caption("ã‚³ãƒ©ãƒ ãƒ†ãƒ¼ãƒã¨å»ºç‰©ã‚¿ã‚¤ãƒ—ã‚’é¸æŠã—ã€é©åˆ‡ãªè¨˜äº‹ã‚’åé›†ã—ã¦AIã§è¦ç´„ã—ã¾ã™ã€‚")

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if "article_results" not in st.session_state:
        st.session_state.article_results = None

    st.subheader("1. ã‚³ãƒ©ãƒ ãƒ†ãƒ¼ãƒé¸æŠ")
    theme = st.selectbox(
        "æ¤œç´¢ã—ãŸã„ã‚³ãƒ©ãƒ ãƒ†ãƒ¼ãƒã‚’é¸æŠã—ã¦ãã ã•ã„",
        options=AVAILABLE_ARTICLE_THEMES,
        index=0,
        key="article_theme",
    )

    st.subheader("2. é€ä»˜å…ˆã®å»ºç‰©ã‚¿ã‚¤ãƒ— (å¿…é ˆ)")
    st.caption("å»ºç‰©ã‚¿ã‚¤ãƒ—ã‚’é¸æŠã™ã‚‹ã¨ã€ãã®å»ºç‰©ã‚¿ã‚¤ãƒ—ã®æ‹…å½“è€…ã«é©ã—ãŸè¨˜äº‹ã®ã¿ã‚’åé›†ã—ã¾ã™")
    building_types = st.multiselect(
        "å»ºç‰©ã‚¿ã‚¤ãƒ—ã‚’é¸æŠ",
        options=BUILDING_TYPES,
        default=[],
        key="article_building_types",
    )

    # å»ºç‰©ã‚¿ã‚¤ãƒ—æœªé¸æŠæ™‚ã®è­¦å‘Š
    if not building_types:
        st.warning("å»ºç‰©ã‚¿ã‚¤ãƒ—ã‚’1ã¤ä»¥ä¸Šé¸æŠã—ã¦ãã ã•ã„")

    # å»ºç‰©ã‚¿ã‚¤ãƒ—ãŒé¸æŠã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿ãƒœã‚¿ãƒ³ã‚’æœ‰åŠ¹åŒ–
    button_disabled = len(building_types) == 0

    if st.button(
        "æ¤œç´¢ãƒ»è¦ç´„ã‚’å®Ÿè¡Œ",
        type="primary",
        key="article_search_button",
        disabled=button_disabled,
    ):
        # åˆ¤å®šãƒ»è¦ç´„ã¨ã‚‚ã«Flash LLMã‚’ä½¿ç”¨ (é«˜é€Ÿãƒ»å®‰ä¾¡)
        flash_llm = resolve_gemini_client_with_model(FLASH_MODEL_NAME)

        if flash_llm is None:
            return

        with st.status("å‡¦ç†ä¸­...", expanded=True) as status:
            # Step 1: é©åˆ‡ãªè¨˜äº‹ã‚’åé›† (Flashã§åˆ¤å®š)
            status.update(label="è¨˜äº‹ã‚’åé›†ãƒ»åˆ¤å®šä¸­...", state="running")

            # é€²æ—è¡¨ç¤ºç”¨ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
            progress_header = st.empty()
            query_display = st.empty()
            article_log = st.empty()
            log_entries: list[str] = []

            def on_progress(info: ArticleProgressInfo) -> None:
                """é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
                # ãƒ˜ãƒƒãƒ€ãƒ¼æ›´æ–°
                progress_header.markdown(
                    f"**åé›†çŠ¶æ³:** {info.total_collected}/{info.target_count}ä»¶ "
                    f"(æ¤œç´¢: {info.total_searched}, åˆ¤å®š: {info.total_judged})"
                )

                if info.event == "query_start":
                    query_display.info(f"ğŸ” æ¤œç´¢ã‚¯ã‚¨ãƒª: {info.query}")
                elif info.event == "article_found":
                    # æœ€æ–°ã®è¨˜äº‹ã‚’è¡¨ç¤º
                    query_display.info(f"ğŸ“„ å–å¾—ä¸­: {info.title[:50]}...")
                elif info.event == "article_judged":
                    # åˆ¤å®šçµæœã‚’ãƒ­ã‚°ã«è¿½åŠ 
                    if info.is_relevant:
                        icon = "âœ…"
                        result_text = "é©åˆ‡"
                    else:
                        icon = "âŒ"
                        result_text = "ä¸é©åˆ‡"
                    # ã‚¿ã‚¤ãƒˆãƒ«ã¨ç†ç”±ã‚’æ”¹è¡Œã—ã¦è¡¨ç¤º
                    log_entry = f"{icon} **[{result_text}]** {info.title}\n" f"   â”” {info.reason}\n"
                    log_entries.append(log_entry)
                    # å…¨ä»¶ã‚’è¡¨ç¤º
                    article_log.markdown("\n".join(log_entries))

            try:
                collection_result = collect_relevant_articles(
                    theme=theme,
                    building_types=building_types,
                    flash_llm=flash_llm,
                    target_count=20,
                    max_search_attempts=10,
                    progress_callback=on_progress,
                )
            except Exception as exc:
                status.update(label="å¤±æ•—", state="error")
                st.error(f"è¨˜äº‹åé›†ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}")
                return

            # åé›†çµ±è¨ˆã‚’è¡¨ç¤º
            stopped_reason_ja = {
                "target_reached": "ç›®æ¨™é”æˆ",
                "max_attempts": "æ¤œç´¢ä¸Šé™",
                "no_more_results": "çµæœãªã—",
            }.get(collection_result.stopped_reason, collection_result.stopped_reason)

            # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ã‚¯ãƒªã‚¢ã—ã¦æœ€çµ‚çµæœã‚’è¡¨ç¤º
            progress_header.empty()
            query_display.empty()
            article_log.empty()

            st.success(
                f"åé›†å®Œäº†: æ¤œç´¢ {collection_result.total_searched}ä»¶ â†’ "
                f"åˆ¤å®š {collection_result.total_judged}ä»¶ â†’ "
                f"é©åˆ‡ {len(collection_result.articles)}ä»¶ "
                f"({stopped_reason_ja})"
            )

            if not collection_result.articles:
                status.update(label="å®Œäº†", state="complete")
                st.warning("é©åˆ‡ãªè¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                return

            # Step 2: é©åˆ‡ãªè¨˜äº‹ã‚’è¦ç´„ (Proã§è¦ç´„)
            status.update(label="è¨˜äº‹ã‚’è¦ç´„ä¸­...", state="running")
            results: list[ArticleOutputRow] = []
            progress_bar = st.progress(0)
            summary_status = st.empty()

            for i, article in enumerate(collection_result.articles):
                # è¦ç´„ä¸­ã®è¨˜äº‹ã‚’è¡¨ç¤º
                summary_status.info(
                    f"ğŸ“ è¦ç´„ä¸­ ({i + 1}/{len(collection_result.articles)}): "
                    f"{article.title[:50]}..."
                )
                try:
                    summary = summarize_article(
                        article.content,
                        flash_llm,
                        title=article.title,
                        url=article.link,
                    )
                    results.append(
                        ArticleOutputRow(
                            theme=theme,
                            title=article.title,
                            content=summary,
                            image=article.og_image,
                            link=article.link,
                        )
                    )
                except Exception as exc:
                    st.warning(f"è¦ç´„ã‚¨ãƒ©ãƒ¼ ({article.link}): {exc}")

                progress_bar.progress((i + 1) / len(collection_result.articles))

            summary_status.empty()

            # Step 3: å“è³ªè©•ä¾¡ã§ä¸Šä½3ä»¶ã«çµã‚Šè¾¼ã¿
            if len(results) > 3:
                status.update(label="å“è³ªè©•ä¾¡ä¸­...", state="running")
                quality_status = st.empty()
                quality_status.info("ğŸ“Š è¦ç´„ã®å“è³ªã‚’è©•ä¾¡ã—ã€ä¸Šä½3ä»¶ã‚’é¸å‡ºä¸­...")

                # è©•ä¾¡ç”¨ã®dictå½¢å¼ã«å¤‰æ›
                summaries_for_eval = [
                    {"theme": r.theme, "title": r.title, "content": r.content} for r in results
                ]

                # å“è³ªè©•ä¾¡ã‚’å®Ÿè¡Œ (ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ˆé ­3ä»¶ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯)
                try:
                    top_indices = evaluate_summary_quality(summaries_for_eval, flash_llm, top_n=3)
                    # ä¸Šä½3ä»¶ã®ã¿ã‚’æŠ½å‡º
                    results = [results[i] for i in top_indices if i < len(results)]
                except Exception as exc:
                    st.warning(f"å“è³ªè©•ä¾¡ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãŸã‚ã€å…ˆé ­3ä»¶ã‚’è¡¨ç¤ºã—ã¾ã™: {exc}")
                    results = results[:3]

                quality_status.empty()

            status.update(label="å®Œäº†", state="complete")

        # çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
        st.session_state.article_results = results

    # çµæœè¡¨ç¤º (ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰)
    if st.session_state.article_results:
        results = st.session_state.article_results

        st.subheader("çµæœ")
        st.success(f"{len(results)}ä»¶ã®è¨˜äº‹ã‚’è¦ç´„ã—ã¾ã—ãŸ")

        # ç”»åƒä»˜ãã‚«ãƒ¼ãƒ‰å½¢å¼ã§è¡¨ç¤º
        st.markdown("#### è¨˜äº‹ä¸€è¦§")
        for row in results:
            with st.container():
                cols = st.columns([1, 3])
                with cols[0]:
                    # ç”»åƒURLãŒå®Œå…¨ãªURLã‹ãƒã‚§ãƒƒã‚¯ (ç›¸å¯¾ãƒ‘ã‚¹ã¯ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹)
                    if row.image and row.image.startswith(("http://", "https://")):
                        try:
                            st.image(row.image, width=150)
                        except Exception:
                            st.markdown("*ç”»åƒèª­è¾¼ã‚¨ãƒ©ãƒ¼*")
                    else:
                        st.markdown("*ç”»åƒãªã—*")
                with cols[1]:
                    st.markdown(f"**{row.title}**")
                    st.caption(f"ãƒ†ãƒ¼ãƒ: {row.theme}")
                    st.markdown(row.content)
                    st.markdown(f"[è¨˜äº‹ã‚’é–‹ã]({row.link})")
                st.divider()

        # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        st.download_button(
            "CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=export_article_search_csv(results),
            file_name="article_search_results.csv",
            mime="text/csv",
            key="article_download_button",
        )

        # çµæœã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
        if st.button("çµæœã‚’ã‚¯ãƒªã‚¢", key="article_clear_button"):
            st.session_state.article_results = None
            st.rerun()


def main() -> None:
    st.set_page_config(page_title="Graph Insight Uploader", layout="wide")

    if not check_password():
        return

    st.title("ã‚°ãƒ©ãƒ•åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

    # ã‚¿ãƒ–ã§æ©Ÿèƒ½ã‚’åˆ†é›¢ (3ã¤ã«æ‹¡å¼µ)
    tab1, tab2, tab3 = st.tabs(["ã‚°ãƒ©ãƒ•åˆ†æ", "é›»åŠ›ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼åˆ†æ", "è¨˜äº‹æ¤œç´¢ãƒ»è¦ç´„"])

    with tab1:
        render_graph_analysis_tab()

    with tab2:
        render_calendar_analysis_tab()

    with tab3:
        render_article_search_tab()


if __name__ == "__main__":
    main()
